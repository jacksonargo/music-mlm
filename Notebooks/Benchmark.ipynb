{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56c6e5af-86c9-421d-8830-082aec24d17e",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d2a73a1-22c7-4b3c-b5a7-b8d312d9e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from transformers import AutoModelForMaskedLM, Trainer, pipeline\n",
    "\n",
    "from model.config import BERT_BASE_UNCASED, DISTILBERT_BASE_UNCASED, MUSIC_MLM, training_args\n",
    "from model.data_collator import data_collator\n",
    "from model.data_split import benchmark_sentences\n",
    "from model.tokenizer import tokenize_sentences, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec2f52b-aa66-4bd5-a790-858a37a144b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModelForMaskedLM.from_pretrained(BERT_BASE_UNCASED)\n",
    "distilbert = AutoModelForMaskedLM.from_pretrained(DISTILBERT_BASE_UNCASED)\n",
    "music_mlm = AutoModelForMaskedLM.from_pretrained(MUSIC_MLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd974f1-e094-450b-b2ba-2079a259ec5c",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e8966c0-9c6a-4580-b9b7-3bcf3c08454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.output_dir = \"benchmark_evaluation\"\n",
    "benchmark_tokens = tokenize_sentences(benchmark_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4903e3c-87c6-42a6-b8ee-e4e43cff48ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model):\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        eval_dataset=benchmark_tokens,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    return trainer.evaluate(benchmark_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74369397-32ff-4081-a96b-5f9a8048f84b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 21246\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='1328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   1/1328 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_evaluation = evaluate_model(bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c085a4e-c676-4503-8e11-fa00d39501d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "distilbert_evaluation = evaluate_model(distilbert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e4060-9fb6-4540-9a14-248ea1220307",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "music_mlm_evaluation = evaluate_model(music_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319a023-7361-4055-94d1-463aa2e92a97",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"BERT: {json.dumps(bert_evaluation, indent=4, sort_keys=True)}\")\n",
    "print(f\"DistilBERT: {json.dumps(distilbert_evaluation, indent=4, sort_keys=True)}\")\n",
    "print(f\"MusicMLM: {json.dumps(music_mlm_evaluation, indent=4, sort_keys=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29818117-972f-4269-85c3-6bb93c6016c7",
   "metadata": {},
   "source": [
    "## Practical Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc11f0-18ed-4563-bd32-146731b5bc62",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "EVAL_SENTENCES = ['The best instrument for recording is [MASK].', 'Increasing the gain produces a [MASK] sound.',\n",
    "                  'Flute is to woodwind as Trumpet is to [MASK].',\n",
    "                  'Intensity is to decibels as frequency is to [MASK].', 'The man worked as a [MASK].',\n",
    "                  'The woman worked as a [MASK].', 'The person worked as a [MASK].']\n",
    "\n",
    "unmaskers = {\n",
    "    \"BERT\": pipeline('fill-mask', model=bert, tokenizer=tokenizer),\n",
    "    \"DistilBERT\": pipeline('fill-mask', model=distilbert, tokenizer=tokenizer),\n",
    "    \"MusicMLM\": pipeline('fill-mask', model=distilbert, tokenizer=tokenizer),\n",
    "}\n",
    "\n",
    "for sentence in EVAL_SENTENCES:\n",
    "    for model_name, unmask in unmaskers.items():\n",
    "        print(f\"{model_name} input: {sentence}\")\n",
    "        print(f\"Result: {json.dumps(unmask(sentence), indent=4, sort_keys=True)}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6a813-23ec-47f1-9914-a58941e3315c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}