{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09e9513e-fbc2-4c24-ab6d-7f04780fd74e",
   "metadata": {},
   "source": [
    "# Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a67d567-8e48-49b6-abe9-47fa408c7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForMaskedLM, Trainer\n",
    "\n",
    "from model.config import DISTILBERT_BASE_UNCASED, training_args\n",
    "from model.data_collator import data_collator\n",
    "from model.data_split import train_sentences\n",
    "from model.tokenizer import tokenize_sentences, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dace912-87ef-422c-856f-dc2c7ba85fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_train_sentences, mini_eval_sentences = train_test_split(train_sentences[0:100])\n",
    "mini_train_tokenized = tokenize_sentences(mini_train_sentences)\n",
    "mini_eval_tokenized = tokenize_sentences(mini_eval_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e57d2871-2922-488b-a95c-68da1f9a3d40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /home/jacksonargo/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.91b885ab15d631bf9cee9dc9d25ece0afd932f2f5130eba28f2055b2220c0333\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.12.5\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/jacksonargo/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
      "All model checkpoint weights were used when initializing DistilBertForMaskedLM.\n",
      "\n",
      "All the weights of DistilBertForMaskedLM were initialized from the model checkpoint at distilbert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "mini_model = AutoModelForMaskedLM.from_pretrained(DISTILBERT_BASE_UNCASED)\n",
    "training_args.output_dir = \"mini_model_training\"\n",
    "\n",
    "mini_trainer = Trainer(\n",
    "    model=mini_model,\n",
    "    args=training_args,\n",
    "    train_dataset=mini_train_tokenized,\n",
    "    eval_dataset=mini_eval_tokenized,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d3715e-4287-4332-acb1-1e971880b251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 75\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25/25 00:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.353678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.390263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.340618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.321254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.182182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to mini_trainer_checkpoint\n",
      "Configuration saved in mini_trainer_checkpoint/config.json\n",
      "Model weights saved in mini_trainer_checkpoint/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "mini_trainer.train()\n",
    "mini_trainer.save_model(\"mini_trainer_checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2dbe0b99-856a-4f2e-ab21-276c8aa102a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 3.3476290702819824,\n",
       " 'eval_runtime': 0.5297,\n",
       " 'eval_samples_per_second': 47.199,\n",
       " 'eval_steps_per_second': 3.776,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d81b583e-3ef6-4227-af20-88d87ffe592c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': \"hello i'm a role model.\",\n",
       "  'score': 0.0874275416135788,\n",
       "  'token': 2535,\n",
       "  'token_str': 'r o l e'},\n",
       " {'sequence': \"hello i'm a business model.\",\n",
       "  'score': 0.04861392825841904,\n",
       "  'token': 2449,\n",
       "  'token_str': 'b u s i n e s s'},\n",
       " {'sequence': \"hello i'm a new model.\",\n",
       "  'score': 0.03383750095963478,\n",
       "  'token': 2047,\n",
       "  'token_str': 'n e w'},\n",
       " {'sequence': \"hello i'm a fashion model.\",\n",
       "  'score': 0.029913591220974922,\n",
       "  'token': 4827,\n",
       "  'token_str': 'f a s h i o n'},\n",
       " {'sequence': \"hello i'm a model model.\",\n",
       "  'score': 0.022853940725326538,\n",
       "  'token': 2944,\n",
       "  'token_str': 'm o d e l'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline('fill-mask', model=mini_model, tokenizer=tokenizer)\n",
    "unmasker(\"Hello I'm a [MASK] model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c69edb76-2fef-4309-a3e7-932a82494891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sequence': 'a speaker tries to compress sounds that are too loud.',\n",
       "  'score': 0.221269890666008,\n",
       "  'token': 5882,\n",
       "  'token_str': 's p e a k e r'},\n",
       " {'sequence': 'a player tries to compress sounds that are too loud.',\n",
       "  'score': 0.05172230675816536,\n",
       "  'token': 2447,\n",
       "  'token_str': 'p l a y e r'},\n",
       " {'sequence': 'a person tries to compress sounds that are too loud.',\n",
       "  'score': 0.04319479689002037,\n",
       "  'token': 2711,\n",
       "  'token_str': 'p e r s o n'},\n",
       " {'sequence': 'a user tries to compress sounds that are too loud.',\n",
       "  'score': 0.04149453341960907,\n",
       "  'token': 5310,\n",
       "  'token_str': 'u s e r'},\n",
       " {'sequence': 'a microphone tries to compress sounds that are too loud.',\n",
       "  'score': 0.03399374708533287,\n",
       "  'token': 15545,\n",
       "  'token_str': 'm i c r o p h o n e'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker(\"A [MASK] tries to compress sounds that are too loud.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172663c2-31a7-48c6-9bcc-8d82ac05d9a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}